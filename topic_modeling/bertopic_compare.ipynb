{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly\n",
    "%pip install matplotlib\n",
    "%pip install bertopic\n",
    "%pip install sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from bertopic.backend import BaseEmbedder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Englishcsv_file_path = '/Users/davideventre/Desktop/telegram_daten/subcorpus_tp1.csv'\n",
    "# Read the CSV file\n",
    "# wort = input(\"Enter the name of the variable: \")\n",
    "# Name of the output folder and the file\n",
    "teilprojekt = ''\n",
    "output_folder_name = ''\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_name):\n",
    "    os.makedirs(output_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the TSV file path\n",
    "filename = ''\n",
    "\n",
    "# Construct the file path (no need for os.getcwd() since a relative path is specified)\n",
    "tsv_file_path = os.path.join(filename)\n",
    "\n",
    "# Read the TSV file\n",
    "df = pd.read_csv(tsv_file_path, sep=',', low_memory=False)\n",
    "\n",
    "# Print the header to know available columns\n",
    "print(df.columns)\n",
    "print(df)\n",
    "# Get the number of rows in the DataFrame\n",
    "num_rows = len(df)\n",
    "\n",
    "# Extract specific columns (adjust column names as needed based on printed header)\n",
    "korpus_content = df['text_content'].astype(str).tolist()\n",
    "korpus_text_date = df['text_date'].astype(str).tolist()\n",
    "korpus_text_source = df['text_source'].astype(str).tolist()\n",
    "korpus_text_id = df['text_id'].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the steps are carried out that determine which models and algorithms are decisive for processing the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines import pipeline\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from safetensors import safe_open\n",
    "import torch\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "#matryoshka_dim = 1024 # How big your embeddings should be, choose from: 64, 128, 256, 512, 768, 1024\n",
    "#model = SentenceTransformer(\"aari1995/German_Semantic_V3\")\n",
    "#embedding_model = pipeline(\"feature-extraction\", model=\"dbmdz/bert-base-german-cased\")\n",
    "#embedding_model = pipeline(model=\"ZurichNLP/swissbert\")\n",
    "#embedding_model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "#embedding_model = AutoModelForMaskedLM.from_pretrained('checkpoint-88500', use_safetensors=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "# n_neighbors: höhere Werte nehmen eine \"globalere\" Perspektive der Embeddings ein (grössere Cluster)\n",
    "# n_neighbors: tiefere Werte nehmen eine \"lokalere\" Perspektive der Embeddings ein\n",
    "# n_components: tiefere Werte beeinflussen die Qualität der Embeddings\n",
    "# n_components: hohe Werte dauern länger und HDBScan braucht länger für die Berechnung\n",
    "\n",
    "dim_model = UMAP(n_neighbors=12, n_components=10, min_dist=0.0, metric='cosine')\n",
    "\n",
    "\n",
    "# Eine schnellere Art die Dimensionen zu reduzieren\n",
    "#dim_model = PCA(n_components=5)\n",
    "#topic_model = BERTopic(umap_model=dim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# min_cluster_size: wie gross die Cluster mindestens sein müssen\n",
    "# min_samples: die Zahl der Outlier, tiefere Zahlen reduzieren die Outlier\n",
    "cluster_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True, min_samples=3)\n",
    "# andere Art des Clustering, das keine Ausreisser produziert\n",
    "#cluster_model = KMeans(n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# min_df: wie oft ein Wort vorkommen muss, bevor es in die Repräsentation gelangt\n",
    "# so kann man bei grossen Dokumenten die Berechnung verkürzen\n",
    "# ngram_range: bestimmt die Länge der Ngrams, die in der Repräsentation erscheinen\n",
    "stopword = []\n",
    "vectorizer_model = CountVectorizer(stop_words=stopword,min_df=3, max_df=0.7)\n",
    "\n",
    "# max_features: topic term matrix wird kontrolliert. anstelle das man min_df einstellen muss\n",
    "#vectorizer_model = CountVectorizer(max_features=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "# man kann folgende Parameter einfügen: \n",
    "# reduce_frequent_words oder BM25\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "# besser mit Stoppwörtern:\n",
    "#ctfidf_model = ClassTfidfTransformer(bm25_weighting=True)\n",
    "#ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verschiedene Repräsentationsmöglichkeiten:\n",
    "# Keywords\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech\n",
    "\n",
    "representation_model = [KeyBERTInspired(top_n_words=10), MaximalMarginalRelevance(diversity=0.3)]\n",
    "# Sprachliche Muster\n",
    "\"\"\" \n",
    "import spacy\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "\n",
    "pos_patterns = [[{'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'POS': 'NOUN'}], [{'POS': 'ADJ'}]]\n",
    "representation_model = PartOfSpeech(spacy_de, pos_patterns=pos_patterns)\n",
    "\"\"\"\n",
    "# möglichst unterschiedliche Wörter\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic, Zero-Shot BERTopic, Guided BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different ways to perform BERTopic modeling:\n",
    "\t1.\tBERTopic: Standard topic modeling, without specifying which topics will appear.\n",
    "\t2.\tZero-Shot BERTopic: Topic modeling in which a specific topic is guaranteed to appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausführung BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = 'smaller_clusters'\n",
    "topic_model = BERTopic(embedding_model=embedding_model, \n",
    "                       representation_model=representation_model, \n",
    "                       umap_model=dim_model, hdbscan_model=cluster_model, vectorizer_model=vectorizer_model, ctfidf_model=ctfidf_model)\n",
    "topic_model.fit(korpus_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file to write the logs\n",
    "with open(f'{output_folder_name}/model_log.txt', 'a') as log_file:\n",
    "    # Log the variables\n",
    "    log_file.write(f'embedding_model: {embedding_model}\\n')\n",
    "    log_file.write(f'dim_model: {dim_model}\\n')\n",
    "    log_file.write(f'cluster_model: {cluster_model}\\n')\n",
    "    log_file.write(f'vectorizer_model: {vectorizer_model}\\n')\n",
    "    log_file.write(f'ctfidf_model: {ctfidf_model}\\n')\n",
    "    log_file.write(f'representation_model: {representation_model}\\n')\n",
    "    # Log additional messages\n",
    "    log_file.write('This is a debug message\\n')\n",
    "    log_file.write('This is an info message\\n')\n",
    "    log_file.write('This is a warning message\\n')\n",
    "    log_file.write('This is an error message\\n')\n",
    "    log_file.write('This is a critical message\\n')\n",
    "\n",
    "    # A function to demonstrate logging in a function\n",
    "    def divide(a, b):\n",
    "        try:\n",
    "            result = a / b\n",
    "            log_file.write(f'Divide {a} by {b} = {result}\\n')\n",
    "            return result\n",
    "        except ZeroDivisionError:\n",
    "            log_file.write('Division by zero error\\n')\n",
    "            return None\n",
    "\n",
    "    # Call the function with sample values\n",
    "    divide(10, 2)\n",
    "    divide(10, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausführung BERTopic Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# We define a number of topics that we know are in the documents\n",
    "zeroshot_topic_list = [\"Solidarität\"\n",
    "\n",
    "stopword = []\n",
    "vectorizer_model = CountVectorizer(stop_words=stopword, ngram_range=(1,3), max_df=0.7)\n",
    "\n",
    "zeroshot_min_similarity=0.37\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    top_n_words=10,\n",
    "    min_topic_size=10,\n",
    "    nr_topics=None,\n",
    "    low_memory=False,\n",
    "    calculate_probabilities=False,\n",
    "    seed_topic_list=None,\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=zeroshot_min_similarity,\n",
    "    umap_model=None,\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    hdbscan_model = KMeans(),\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    representation_model=KeyBERTInspired()\n",
    ")\n",
    "\n",
    "# Open a file to write the logs\n",
    "with open(f'{output_folder_name}/model_log.txt', 'a') as log_file:\n",
    "    # Log the variables\n",
    "    log_file.write(f'embedding_model: {embedding_model}\\n')\n",
    "    log_file.write(f'dim_model: {dim_model}\\n')\n",
    "    log_file.write(f'cluster_model: {cluster_model}\\n')\n",
    "    log_file.write(f'vectorizer_model: {vectorizer_model}\\n')\n",
    "    log_file.write(f'ctfidf_model: {ctfidf_model}\\n')\n",
    "    log_file.write(f'representation_model: {representation_model}\\n')\n",
    "    log_file.write(f'cluster_model: {zeroshot_topic_list}\\n')\n",
    "    log_file.write(f'ctfidf_model: {zeroshot_min_similarity}\\n')\n",
    "    # Log additional messages\n",
    "    log_file.write('This is a debug message\\n')\n",
    "    log_file.write('This is an info message\\n')\n",
    "    log_file.write('This is a warning message\\n')\n",
    "    log_file.write('This is an error message\\n')\n",
    "    log_file.write('This is a critical message\\n')\n",
    "\n",
    "    # A function to demonstrate logging in a function\n",
    "    def divide(a, b):\n",
    "        try:\n",
    "            result = a / b\n",
    "            log_file.write(f'Divide {a} by {b} = {result}\\n')\n",
    "            return result\n",
    "        except ZeroDivisionError:\n",
    "            log_file.write('Division by zero error\\n')\n",
    "            return None\n",
    "\n",
    "    # Call the function with sample values\n",
    "    divide(10, 2)\n",
    "    divide(10, 0)\n",
    "\n",
    "topics, _ = topic_model.fit_transform(korpus_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving of the model, so one does not have to run it twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 - safetensors\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "topic_model.save(\"model_solidarität_orgspende_tp2\", serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 - pytorch\n",
    "embedding_model = embedding_model\n",
    "topic_model.save(\"model\", serialization=\"pytorch\", save_ctfidf=True, save_embedding_model=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from directory\n",
    "topic_model = BERTopic.load(\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(korpus_content)\n",
    "topic_model_distr = BERTopic().fit(korpus_content)\n",
    "# Reduce outliers\n",
    "new_topics = topic_model.reduce_outliers(korpus_content, topics)\n",
    "# versions of dependencies and python used. loading and saving model => same dependencies and python\n",
    "# saved in one version of Bertopic should not be loaded in others\n",
    "#topic_model = BERTopic.load(\"meditopic_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_topics_html(model, output_folder_name, m, text_content, text_date, text_source, text_id):\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    # Assuming topic_info is a list of dictionaries with keys like 'document_id', 'topic_distribution', etc.\n",
    "    # Saving the data to a .txt file\n",
    "    topic_data = pd.DataFrame(topic_info)\n",
    "    csv_file_path1 = os.path.join(output_folder_name, m + '_topic_list' + '.csv')\n",
    "    topic_data.to_csv(csv_file_path1, index=False)  # Set index=False to exclude row indices in the output\n",
    "\n",
    "visualize_and_save_topics_html(topic_model, output_folder_name, teilprojekt, korpus_content, korpus_text_id, korpus_text_date, korpus_text_source)#, korpus_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_topics_html(model, output_folder_name, m, text_content, text_id, text_date, text_source):\n",
    "    meta_data_id = {}\n",
    "    meta_data_id['text_id'] = text_id\n",
    "    meta_data_id['text_date'] = text_date\n",
    "    meta_data_id['text_source'] = text_source\n",
    "    topic_info = model.get_document_info(text_content, metadata=meta_data_id)\n",
    "    # Assuming topic_info is a list of dictionaries with keys like 'document_id', 'topic_distribution', etc.\n",
    "    # Saving the data to a .txt file\n",
    "    topic_data = pd.DataFrame(topic_info)\n",
    "    csv_file_path1 = os.path.join(output_folder_name, m + '_list' + '.csv')\n",
    "    topic_data.to_csv(csv_file_path1, index=False)  # Set index=False to exclude row indices in the output\n",
    "\n",
    "visualize_and_save_topics_html(topic_model, output_folder_name, teilprojekt, korpus_content, korpus_text_id, korpus_text_date, korpus_text_source)#, korpus_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_barchart_topics(model, output_folder_name, m):\n",
    "    fig0 = model.visualize_topics()\n",
    "    # Convert the figure to HTML\n",
    "    html0 = pio.to_html(fig0)\n",
    "    html_file_path0 = os.path.join(output_folder_name, m + '_topics' + '.html')\n",
    "    with open(html_file_path0, 'w') as f:\n",
    "        f.write(html0)\n",
    "    \n",
    "\n",
    "visualize_and_save_barchart_topics(topic_model, output_folder_name, teilprojekt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_barchart_topics(model, output_folder_name, m):\n",
    "    fig0 = model.visualize_term_rank()\n",
    "    # Convert the figure to HTML\n",
    "    html0 = pio.to_html(fig0)\n",
    "    html_file_path0 = os.path.join(output_folder_name, m + '_term_rank' + '.html')\n",
    "    with open(html_file_path0, 'w') as f:\n",
    "        f.write(html0)\n",
    "    \n",
    "\n",
    "visualize_and_save_barchart_topics(topic_model, output_folder_name, teilprojekt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_barchart_topics(model, output_folder_name, m):\n",
    "    fig0 = model.visualize_barchart(top_n_topics=20, n_words=20)\n",
    "    # Convert the figure to HTML\n",
    "    html0 = pio.to_html(fig0)\n",
    "    html_file_path0 = os.path.join(output_folder_name, m + '_barchart' + '.html')\n",
    "    with open(html_file_path0, 'w') as f:\n",
    "        f.write(html0)\n",
    "    \n",
    "\n",
    "visualize_and_save_barchart_topics(topic_model, output_folder_name, teilprojekt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize and save heatmap\n",
    "def visualize_and_save_heatmap(model, output_folder_name, m):\n",
    "    heatmap = model.visualize_heatmap()\n",
    "    html4 = pio.to_html(heatmap)\n",
    "    html_file_path3 = os.path.join(output_folder_name, m + '_heatmap' + '.html')\n",
    "    with open(html_file_path3, 'w') as f:\n",
    "        f.write(html4)\n",
    "\n",
    "visualize_and_save_heatmap(topic_model, output_folder_name, teilprojekt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_hierarchical_topics(model, output_folder_name, m, korpus_content):\n",
    "    try:\n",
    "        hierarchical_topics = model.hierarchical_topics(korpus_content)\n",
    "        fig2 = model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)\n",
    "        html2 = pio.to_html(fig2)\n",
    "        html_file_path2 = os.path.join(output_folder_name, m + '_hierarchical' + '.html')\n",
    "        with open(html_file_path2, 'w') as f:\n",
    "            f.write(html2)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "visualize_and_save_hierarchical_topics(topic_model, output_folder_name, teilprojekt, korpus_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_hierarchical_topics(model, output_folder_name, m, korpus_content):\n",
    "    try:\n",
    "        hierarchical_topics = model.hierarchical_topics(korpus_content)\n",
    "        fig2 = model.visualize_hierarchical_documents(korpus_content, hierarchical_topics)\n",
    "        html2 = pio.to_html(fig2)\n",
    "        html_file_path2 = os.path.join(output_folder_name, m + '_hierarchical_documents' + '.html')\n",
    "        with open(html_file_path2, 'w') as f:\n",
    "            f.write(html2)\n",
    "    except TypeError:\n",
    "        pass\n",
    "visualize_and_save_hierarchical_topics(topic_model, output_folder_name, teilprojekt, korpus_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_hierarchical_topics(model, output_folder_name, m, korpus_content):\n",
    "    try:\n",
    "        hierarchical_topics = model.hierarchical_topics(korpus_content)\n",
    "        tree = model.get_topic_tree(hierarchical_topics)\n",
    "        print(tree)\n",
    "    except TypeError:\n",
    "        pass\n",
    "visualize_and_save_hierarchical_topics(topic_model, output_folder_name, teilprojekt, korpus_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = topic_model.topics_over_time(korpus_content, korpus_text_date, nr_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import plotly.io as pio\n",
    "\n",
    "def visualize_clusters(model, output_folder_name, m, korpus_content, text_date):\n",
    "    try:\n",
    "        # Ensure that text_date is in a consistent format\n",
    "        # Attempt to parse the date using pandas, handling various formats\n",
    "        formatted_dates = pd.to_datetime(text_date, errors='coerce', format='mixed')\n",
    "\n",
    "        # Check for any NaT (Not a Time) in formatted_dates which indicates failed parsing\n",
    "        if formatted_dates.isnull().any():\n",
    "            # Handle dates that couldn't be parsed, you can choose to fill them with a default date\n",
    "            # or drop those entries depending on your requirements\n",
    "            print(\"Some dates could not be parsed and will be excluded.\")\n",
    "            # Example: Drop rows with unparsable dates\n",
    "            valid_indices = ~formatted_dates.isnull()\n",
    "            formatted_dates = formatted_dates[valid_indices]\n",
    "            korpus_content = [content for i, content in enumerate(korpus_content) if valid_indices[i]]\n",
    "\n",
    "        topics_over_time = model.topics_over_time(korpus_content, formatted_dates, nr_bins=100)\n",
    "        fig1 = model.visualize_topics_over_time(topics_over_time, top_n_topics=100)\n",
    "        html1 = pio.to_html(fig1)\n",
    "        html_file_path1 = os.path.join(output_folder_name, m + 'dynamic_loaded' + '.html')\n",
    "        with open(html_file_path1, 'w') as f:\n",
    "            f.write(html1)\n",
    "    except (IndexError, ValueError) as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "visualize_clusters(topic_model, output_folder_name, teilprojekt, korpus_content, korpus_text_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(model, output_folder_name, m, korpus_content, text_date):\n",
    "    try:\n",
    "        topics_over_time = model.topics_over_time(korpus_content, text_date, nr_bins=100)\n",
    "        fig1 = model.visualize_topics_over_time(topics_over_time, top_n_topics=100)\n",
    "        html1 = pio.to_html(fig1)\n",
    "        html_file_path1 = os.path.join(output_folder_name, m + 'dynamic_loaded' + '.html')\n",
    "        with open(html_file_path1, 'w') as f:\n",
    "            f.write(html1)\n",
    "    except IndexError or ValueError:\n",
    "        print('ValueError: Expected 2D array, got scalar array instead')\n",
    "        pass\n",
    "\n",
    "visualize_clusters(topic_model, output_folder_name, teilprojekt, korpus_content, korpus_text_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#korpus_embeddings = embedding_model.encode(korpus_content, show_progress_bar=True)\n",
    "korpus_embeddings = embedding_model(korpus_content, show_progress_bar=True)\n",
    "\n",
    "def visualize_clusters(model, output_folder_name, m, korpus_content, embeddings):\n",
    "    try:\n",
    "        visualize_docs = model.visualize_documents(korpus_content, embeddings=embeddings, hide_annotations=True, hide_document_hover=True, width=2400, height=1400)\n",
    "        html_file_path7 = os.path.join(output_folder_name, m + '_documents' + '.html')\n",
    "        html3 = pio.to_html(visualize_docs)\n",
    "        with open(html_file_path7, 'w') as f:\n",
    "            f.write(html3)\n",
    "    except IndexError:\n",
    "        try:\n",
    "            print('ValueError')    \n",
    "            pass\n",
    "        except TypeError:\n",
    "            pass\n",
    "    # Get document info\n",
    "    \n",
    "visualize_clusters(topic_model, output_folder_name, teilprojekt, korpus_content, korpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_barchart_topics(model, output_folder_name, m):\n",
    "    fig0 = model.visualize_document_datamap()\n",
    "    # Convert the figure to HTML\n",
    "    html0 = pio.to_html(fig0)\n",
    "    html_file_path0 = os.path.join(output_folder_name, m + '_datamap' + '.html')\n",
    "    with open(html_file_path0, 'w') as f:\n",
    "        f.write(html0)\n",
    "    \n",
    "\n",
    "visualize_and_save_barchart_topics(topic_model, output_folder_name, teilprojekt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(model, output_folder_name, m, korpus_content, classes):\n",
    "    # Topics ordered by a specific class \n",
    "    try:\n",
    "        topics_per_class = model.topics_per_class(korpus_content, classes=classes)\n",
    "        visualize_class = model.visualize_topics_per_class(topics_per_class, top_n_topics=10)\n",
    "        html5 = pio.to_html(visualize_class)\n",
    "        html_file_path5 = os.path.join(output_folder_name, m + '_class' + '.html')\n",
    "        with open(html_file_path5, 'w') as f:\n",
    "            f.write(html5)\n",
    "    except IndexError:\n",
    "        print(f'ValueError: Expected 2D array, got scalar array instead:')\n",
    "        pass\n",
    "visualize_clusters(topic_model, output_folder_name, teilprojekt, korpus_content, korpus_text_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Topics in Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(model, output_folder_name, m, text_content):\n",
    "    # Topics ordered by a specific class \n",
    "    try:\n",
    "        topic_distr, _ = model.approximate_distribution(text_content)\n",
    "        visualize_class = model.visualize_distribution(topic_distr[0])\n",
    "        html5 = pio.to_html(visualize_class)\n",
    "        html_file_path5 = os.path.join(output_folder_name, '_distribution' + '.html')\n",
    "        with open(html_file_path5, 'w') as f:\n",
    "            f.write(html5)\n",
    "    except ValueError:\n",
    "        print(f'NotFittedError: Vocabulary not fitted or provided')\n",
    "        pass\n",
    "visualize_clusters(topic_model, output_folder_name, \"korpus\", korpus_content)#, korpus1_embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bertopic1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
